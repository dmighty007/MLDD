{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NuN9jLtU0NQ0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "li5x0riE2xQX"
   },
   "source": [
    "# Lab 7 - Introduction to PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shmZsfip3JI2"
   },
   "source": [
    "Tensors are data structures that are similar to arrays and matrices. Tensors are similar to NumPy arrays and they can run on GPUs or other specialized hardware to accelerate computing. PyTorch is a machine learning framework that allows us to create, train, and test models. In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model’s parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8wdVVZ4A37bl"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IqwzSgq3sQd"
   },
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4sePIyHn3xLE"
   },
   "source": [
    "### Creating a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pFvegjEA3tat",
    "outputId": "935537ae-42d0-4dda-cb62-0a70142e86fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor from data: \n",
      " tensor([[1, 2],\n",
      "        [3, 4]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating tensors from data\n",
    "\n",
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "\n",
    "print(f\"Tensor from data: \\n {x_data} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dmbTKYKjzC-r",
    "outputId": "d837d9df-e131-4bf6-c49a-48d47b90e007"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor from NumPy array: \n",
      " tensor([[1, 2],\n",
      "        [3, 4]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating tensors from a NumPy array\n",
    "\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "\n",
    "print(f\"Tensor from NumPy array: \\n {x_np} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rfl0m-Aq4jUC",
    "outputId": "f117757a-195e-40c5-d98e-dff75a0d73ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor of shape (2, 3): \n",
      "tensor([[0.0936, 0.6726, 0.8078],\n",
      "        [0.7598, 0.4147, 0.0898]])\n",
      "\n",
      "Ones Tensor of shape (2, 3): \n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "Zero Tensor of shape (2, 3): \n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create tensors of a specific shape\n",
    "\n",
    "shape = (2, 3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor of shape {shape}: \\n{rand_tensor}\\n\")\n",
    "print(f\"Ones Tensor of shape {shape}: \\n{ones_tensor}\\n\")\n",
    "print(f\"Zero Tensor of shape {shape}: \\n{zeros_tensor}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-_XJKcrJ39h5",
    "outputId": "b2234a8c-ef18-47e0-9ef7-5af4657f41c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor filled with 1's, with the shape of some other tensor\n",
    "\n",
    "x_ones = torch.ones_like(x_data)\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VsJ5Og5_4T7Z",
    "outputId": "05185023-4d07-4bb1-cfb8-cc41b707c392"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.1273, 0.5321],\n",
      "        [0.6923, 0.0168]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor filled random numbers, with the shape of some other tensor\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float)\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65UEIvBv6Krh"
   },
   "source": [
    "### Tensor Attributes and Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jcIkltoM4eOo",
    "outputId": "dd8b5f8c-ab4e-41a4-ad4c-f8140833e632"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Size  of tensor: torch.Size([3, 4]) (same as shape)\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "# Getting attributes of a tensor\n",
    "\n",
    "tensor = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Size  of tensor: {tensor.size()} (same as shape)\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ytI2jlOj5-Gf",
    "outputId": "80455909-8ad6-4dae-ad9c-e964d54bd142"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device tensor is stored on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Almost all tensor operations are typically much faster on a GPU/TPU, when compared to a CPU\n",
    "# Getting a GPU for Google Colab Notebooks: Go to Edit -> Notebook Settings -> Hardware accelerator\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  tensor = tensor.to('cuda')\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BGABPVBW9yb3",
    "outputId": "3c5dbf15-5760-4470-df6a-186cde95d59c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor: \n",
      " tensor([[0.2447, 0.9544, 0.0597, 0.7642],\n",
      "        [0.8241, 0.6032, 0.0464, 0.4630],\n",
      "        [0.4666, 0.7372, 0.0474, 0.2222]]) \n",
      "\n",
      "New Tensor: \n",
      " tensor([[0.2447],\n",
      "        [0.9544],\n",
      "        [0.0597],\n",
      "        [0.7642],\n",
      "        [0.8241],\n",
      "        [0.6032],\n",
      "        [0.0464],\n",
      "        [0.4630],\n",
      "        [0.4666],\n",
      "        [0.7372],\n",
      "        [0.0474],\n",
      "        [0.2222]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Changing dimensions of a tensor\n",
    "\n",
    "tensor = torch.rand(3, 4)\n",
    "new_tensor = tensor.view(12, 1)\n",
    "print(f\"Original Tensor: \\n {tensor} \\n\")\n",
    "print(f\"New Tensor: \\n {new_tensor} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hHw3XYLn6YRw",
    "outputId": "5bed5b28-09be-4b11-b409-4b5c465499b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 0., 1.],\n",
      "        [1., 1., 0., 1.],\n",
      "        [1., 1., 0., 1.],\n",
      "        [1., 1., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor splicing and indexing, just like how it is done in NumPy\n",
    "\n",
    "tensor = torch.ones(4, 4)\n",
    "tensor[:,2] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jbd_7MVh65Of",
    "outputId": "e6b06e3c-9578-4498-fcfe-e0bb611a483e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated Tensor: \n",
      " tensor([[1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.],\n",
      "        [1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.],\n",
      "        [1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.],\n",
      "        [1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.]]) \n",
      "\n",
      "Stacked Tensor: \n",
      " tensor([[[1., 1., 0., 1.],\n",
      "         [1., 1., 0., 1.],\n",
      "         [1., 1., 0., 1.],\n",
      "         [1., 1., 0., 1.]],\n",
      "\n",
      "        [[1., 1., 0., 1.],\n",
      "         [1., 1., 0., 1.],\n",
      "         [1., 1., 0., 1.],\n",
      "         [1., 1., 0., 1.]],\n",
      "\n",
      "        [[1., 1., 0., 1.],\n",
      "         [1., 1., 0., 1.],\n",
      "         [1., 1., 0., 1.],\n",
      "         [1., 1., 0., 1.]]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tensor `stack` and `cat` operations\n",
    "\n",
    "# Concatenates along a given dimension\n",
    "cat_tensor = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(f\"Concatenated Tensor: \\n {cat_tensor} \\n\")\n",
    "\n",
    "# Concatenates along a new dimension\n",
    "stack_tensor = torch.stack([tensor, tensor, tensor])\n",
    "print(f\"Stacked Tensor: \\n {stack_tensor} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MeobuwDB7Ubc",
    "outputId": "fe068154-fe4f-4282-ea40-7fc1b2b914c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: \n",
      " tensor([[1., 1., 0., 1.],\n",
      "        [1., 1., 0., 1.],\n",
      "        [1., 1., 0., 1.],\n",
      "        [1., 1., 0., 1.]]) \n",
      "\n",
      "Multiplied Tensor: \n",
      " tensor([[1., 1., 0., 1.],\n",
      "        [1., 1., 0., 1.],\n",
      "        [1., 1., 0., 1.],\n",
      "        [1., 1., 0., 1.]]) \n",
      "\n",
      "Multiplied Tensor: \n",
      " tensor([[1., 1., 0., 1.],\n",
      "        [1., 1., 0., 1.],\n",
      "        [1., 1., 0., 1.],\n",
      "        [1., 1., 0., 1.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Element-wise tensor multiplication\n",
    "\n",
    "print(f\"Tensor: \\n {tensor} \\n\")\n",
    "print(f\"Multiplied Tensor: \\n {tensor.mul(tensor)} \\n\")\n",
    "print(f\"Multiplied Tensor: \\n {tensor * tensor} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sRF1tqSN86TC",
    "outputId": "535aa087-445a-410d-ad7a-6f31f3c7208f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: \n",
      " tensor([[1., 1., 0., 1.],\n",
      "        [1., 1., 0., 1.],\n",
      "        [1., 1., 0., 1.],\n",
      "        [1., 1., 0., 1.]]) \n",
      "\n",
      "Multiplied Tensor: \n",
      " tensor([[3., 3., 0., 3.],\n",
      "        [3., 3., 0., 3.],\n",
      "        [3., 3., 0., 3.],\n",
      "        [3., 3., 0., 3.]]) \n",
      "\n",
      "Multiplied Tensor: \n",
      " tensor([[3., 3., 0., 3.],\n",
      "        [3., 3., 0., 3.],\n",
      "        [3., 3., 0., 3.],\n",
      "        [3., 3., 0., 3.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication for tensors\n",
    "\n",
    "print(f\"Tensor: \\n {tensor} \\n\")\n",
    "print(f\"Multiplied Tensor: \\n {tensor.matmul(tensor)} \\n\")\n",
    "print(f\"Multiplied Tensor: \\n {tensor @ tensor} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "onDUJ1a-9dcu",
    "outputId": "ddb8e87a-5102-4a12-a274-b252439ba3d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: \n",
      " tensor([[1., 1., 0., 1.],\n",
      "        [1., 1., 0., 1.],\n",
      "        [1., 1., 0., 1.],\n",
      "        [1., 1., 0., 1.]]) \n",
      "\n",
      "Multiplied Tensor: \n",
      " tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]]) \n",
      "\n",
      "Multiplied Tensor: \n",
      " tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication for tensors\n",
    "\n",
    "print(f\"Tensor: \\n {tensor} \\n\")\n",
    "print(f\"Multiplied Tensor: \\n {tensor.matmul(tensor.T)} \\n\")\n",
    "print(f\"Multiplied Tensor: \\n {tensor @ tensor.T} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TEVYBwLN8WAr",
    "outputId": "9502f928-2e95-4f3f-cd24-e57bfcffe682"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11., 11., 10., 11.],\n",
      "        [11., 11., 10., 11.],\n",
      "        [11., 11., 10., 11.],\n",
      "        [11., 11., 10., 11.]]) \n",
      "\n",
      "tensor([[16., 16., 15., 16.],\n",
      "        [16., 16., 15., 16.],\n",
      "        [16., 16., 15., 16.],\n",
      "        [16., 16., 15., 16.]])\n"
     ]
    }
   ],
   "source": [
    "# Inplace operations for tensors, problematic when computing derivatives because of an immediate loss of history\n",
    "\n",
    "print(tensor, \"\\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36rqqr7d-vKj"
   },
   "source": [
    "### Autograd for tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZI5-3n1-3CQ"
   },
   "source": [
    "Autograd is now a core torch package for automatic differentiation. It uses a tape based system for automatic differentiation. In autograd, if any input Tensor of an operation has requires_grad=True, the computation will be tracked. In the forward phase, the autograd tape will remember all the operations it executed, and in the backward phase, it will replay the operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JOjfAk_4-2hJ",
    "outputId": "ec3ef67b-eae8-408d-9801-60a26f2b3e40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1XSSH-go_vsb",
    "outputId": "14968d79-236f-4b7f-a7c7-e2e2c90503d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>) <AddBackward0 object at 0x7efb3edee850>\n"
     ]
    }
   ],
   "source": [
    "# The tensor y is created via an addition operation\n",
    "y = x + 2\n",
    "print(y, y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-4aF1N6a_0U8",
    "outputId": "8b76dc44-c715-43cd-abe5-100ab317da4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9., 9.],\n",
      "        [9., 9.]], grad_fn=<MulBackward0>) <MulBackward0 object at 0x7efb3eedbc50>\n",
      "tensor([[18., 18.],\n",
      "        [18., 18.]], grad_fn=<MmBackward0>) <MmBackward0 object at 0x7efb3eedbc50>\n",
      "tensor([[9., 9.],\n",
      "        [9., 9.]], grad_fn=<PowBackward0>) <PowBackward0 object at 0x7efb3eedbc50>\n"
     ]
    }
   ],
   "source": [
    "# The tensor y is created via a multiplication operation\n",
    "\n",
    "b = (y * y)\n",
    "print(b, b.grad_fn)\n",
    "\n",
    "# The tensor y is created via a matrix multiplication operation\n",
    "\n",
    "b = (y @ y)\n",
    "print(b, b.grad_fn)\n",
    "\n",
    "# The tensor y is created via a power operation\n",
    "\n",
    "b = (y ** 2)\n",
    "print(b, b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wqLyMEWHATR7",
    "outputId": "d9d005a7-3f97-4e1c-ed49-ecef04559f11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print((x ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0gIRA5JyAqUp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6bTNmEFl06C1"
   },
   "source": [
    "## Writing a Simple Neural Network with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSTYmvrx5rki"
   },
   "source": [
    "#### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TPqIJjsM5rRd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uP5aF1YT1Rf2"
   },
   "source": [
    "### Define a Neural network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vr7yH04G1PTs",
    "outputId": "8f287765-90a0-4402-f4a7-36f96f570e1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        \n",
    "        n_features = 512\n",
    "        \n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "        nn.Linear(n_features, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 1),\n",
    "    )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYtVt-WX1ecJ"
   },
   "source": [
    "#### Running the above neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6t6_bAYY1UUQ",
    "outputId": "515eaf8d-9b1a-46c6-c221-533d1215473b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([[ 0.0008],\n",
      "        [-0.0400],\n",
      "        [-0.0390],\n",
      "        [-0.0653],\n",
      "        [-0.0525],\n",
      "        [-0.0667],\n",
      "        [-0.0205],\n",
      "        [-0.0420],\n",
      "        [-0.0463],\n",
      "        [-0.0145]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "n_features = 512\n",
    "X = torch.rand(10, n_features, device=device)\n",
    "\n",
    "predictions = model(X)\n",
    "print(f\"Predicted class: {predictions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CuXyKeJU0-Ii"
   },
   "source": [
    "#### Breaking down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YhVxSaBv2wnG",
    "outputId": "39bf4a2e-4db2-46c1-a0e6-2b7a7470eb57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 512])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.rand(10, n_features, device=device)\n",
    "print(input_tensor.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "meVBFyN8291A"
   },
   "source": [
    "#### A linear layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9m1Bu0Qn2_n3",
    "outputId": "823ae3a3-03d8-4c06-c1a1-79332bfe4f39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 256])\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features=n_features, out_features=256).to(device)\n",
    "hidden1 = layer1(input_tensor)\n",
    "print(hidden1.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6leoEn53At3"
   },
   "source": [
    "#### Activation function\n",
    "\n",
    "Non-linear activations are what create the complex mappings between the model’s inputs and outputs. They are applied after linear transformations to introduce nonlinearity, helping neural networks learn a wide variety of phenomena.\n",
    "\n",
    "\n",
    "We Use the ReLU activation function here. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IOAQ4dg33FHp",
    "outputId": "26bff8f4-cb17-407d-c07e-7a9beeae4c28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[-0.3035,  0.1893,  0.4050,  ..., -0.0494, -0.5079,  0.3359],\n",
      "        [-0.2047, -0.0540, -0.0645,  ...,  0.2083, -0.1241,  0.3469],\n",
      "        [-0.2541, -0.1377, -0.0246,  ..., -0.0854, -0.3087,  0.4069],\n",
      "        ...,\n",
      "        [-0.3571,  0.0507, -0.1421,  ...,  0.1342, -0.5627,  0.0896],\n",
      "        [ 0.0119, -0.0150,  0.2757,  ...,  0.0856, -0.3203,  0.0565],\n",
      "        [-0.5549, -0.0077,  0.2778,  ...,  0.3448, -0.5390, -0.0488]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.0000, 0.1893, 0.4050,  ..., 0.0000, 0.0000, 0.3359],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.2083, 0.0000, 0.3469],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.4069],\n",
      "        ...,\n",
      "        [0.0000, 0.0507, 0.0000,  ..., 0.1342, 0.0000, 0.0896],\n",
      "        [0.0119, 0.0000, 0.2757,  ..., 0.0856, 0.0000, 0.0565],\n",
      "        [0.0000, 0.0000, 0.2778,  ..., 0.3448, 0.0000, 0.0000]],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PdkzUKgC3QgU"
   },
   "source": [
    "#### Pytorch Sequential module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MCQhtKOW3Uh1",
    "outputId": "796e3277-92c2-4e8a-ef52-e2c607104a99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1510],\n",
      "        [-0.0480],\n",
      "        [-0.1422],\n",
      "        [ 0.0507],\n",
      "        [-0.1209],\n",
      "        [-0.0808],\n",
      "        [ 0.0631],\n",
      "        [ 0.0565],\n",
      "        [ 0.0648],\n",
      "        [-0.1106]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 1)\n",
    ").to(device)\n",
    "\n",
    "\n",
    "input_tensor = torch.rand(10,n_features, device=device)\n",
    "logits = seq_modules(input_tensor)\n",
    "print(logits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jRvRw6r3fdk"
   },
   "source": [
    "#### Last layer for prediction\n",
    "\n",
    "Since this is a regression task, no activation function is required for last layer.\n",
    "\n",
    "In a classification task, the last linear layer of the neural network returns logits - raw values in [-infty, infty]. The are passed to the nn.Softmax module and the logits are scaled to values [0, 1] representing the model’s predicted probabilities for each class. dim parameter indicates the dimension along which the values must sum to 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h_hA79g53WlI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xEmV6XEP3nNy"
   },
   "source": [
    "#### Neural Network parameters\n",
    "\n",
    "Layers inside a neural network are parameterized, i.e. have associated weights and biases that are optimized during training. Subclassing nn.Module automatically tracks all fields defined inside your model object, and makes all parameters accessible using your model’s parameters() or named_parameters() methods.\n",
    "\n",
    "In this example, we iterate over each parameter, and print its size and a preview of its values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Pe0-nG03jLc",
    "outputId": "a3391421-557f-4745-99ac-6926d8cdc57b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([256, 512]) | Values : tensor([[-0.0430, -0.0385, -0.0381,  ..., -0.0442, -0.0035,  0.0032],\n",
      "        [-0.0386,  0.0177,  0.0319,  ...,  0.0089,  0.0431, -0.0330]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([256]) | Values : tensor([-0.0222, -0.0281], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([128, 256]) | Values : tensor([[-0.0303, -0.0112,  0.0470, -0.0317,  0.0123, -0.0117, -0.0432,  0.0420,\n",
      "          0.0117,  0.0582, -0.0577, -0.0357, -0.0451, -0.0578, -0.0235, -0.0568,\n",
      "         -0.0503, -0.0112,  0.0198, -0.0409, -0.0571, -0.0284, -0.0044,  0.0216,\n",
      "         -0.0510, -0.0211, -0.0220, -0.0443, -0.0451, -0.0520,  0.0136,  0.0410,\n",
      "         -0.0604, -0.0552,  0.0171,  0.0243, -0.0153,  0.0280, -0.0378, -0.0610,\n",
      "         -0.0375, -0.0113, -0.0485, -0.0557, -0.0044, -0.0318, -0.0082,  0.0546,\n",
      "          0.0098,  0.0579,  0.0582, -0.0392,  0.0401,  0.0112, -0.0237,  0.0409,\n",
      "         -0.0210,  0.0554,  0.0400,  0.0527, -0.0584, -0.0078, -0.0565, -0.0460,\n",
      "         -0.0088,  0.0120, -0.0204, -0.0003, -0.0253, -0.0179, -0.0222,  0.0189,\n",
      "         -0.0199,  0.0158,  0.0050, -0.0622, -0.0199,  0.0380,  0.0022,  0.0532,\n",
      "         -0.0065, -0.0235, -0.0065, -0.0106, -0.0119, -0.0415, -0.0467, -0.0605,\n",
      "         -0.0478, -0.0188, -0.0418,  0.0563,  0.0328, -0.0079, -0.0149,  0.0126,\n",
      "         -0.0272,  0.0603, -0.0364, -0.0001, -0.0240, -0.0409, -0.0604, -0.0454,\n",
      "         -0.0541, -0.0235, -0.0454, -0.0522,  0.0165,  0.0573, -0.0225,  0.0233,\n",
      "          0.0457,  0.0474, -0.0054, -0.0581,  0.0448,  0.0457, -0.0151, -0.0020,\n",
      "         -0.0354,  0.0002, -0.0064, -0.0050,  0.0620, -0.0184, -0.0527, -0.0468,\n",
      "         -0.0183,  0.0018, -0.0090, -0.0192,  0.0093,  0.0506,  0.0278, -0.0112,\n",
      "         -0.0567,  0.0522, -0.0245, -0.0500, -0.0280,  0.0237, -0.0028,  0.0191,\n",
      "          0.0296, -0.0211, -0.0414, -0.0187, -0.0554, -0.0061, -0.0307, -0.0519,\n",
      "          0.0238, -0.0100, -0.0237, -0.0397,  0.0439,  0.0435, -0.0038, -0.0330,\n",
      "          0.0130, -0.0557, -0.0311, -0.0244, -0.0434,  0.0188, -0.0111, -0.0170,\n",
      "         -0.0076,  0.0323,  0.0102, -0.0314, -0.0290, -0.0144,  0.0526,  0.0542,\n",
      "         -0.0042, -0.0449, -0.0076,  0.0180, -0.0019, -0.0155, -0.0205,  0.0417,\n",
      "          0.0341, -0.0088,  0.0328,  0.0132,  0.0229,  0.0107, -0.0411, -0.0184,\n",
      "         -0.0007, -0.0145, -0.0352,  0.0285, -0.0559, -0.0332, -0.0458,  0.0408,\n",
      "          0.0592,  0.0382,  0.0110, -0.0149, -0.0616,  0.0371, -0.0265,  0.0285,\n",
      "          0.0412,  0.0324, -0.0198,  0.0372,  0.0403,  0.0312,  0.0465, -0.0172,\n",
      "          0.0187,  0.0181,  0.0273,  0.0502,  0.0176, -0.0059,  0.0293,  0.0483,\n",
      "          0.0423, -0.0229,  0.0098,  0.0108, -0.0219,  0.0491,  0.0230, -0.0012,\n",
      "          0.0437, -0.0326,  0.0514,  0.0082,  0.0456, -0.0417,  0.0200, -0.0449,\n",
      "          0.0586, -0.0072,  0.0107, -0.0549,  0.0364, -0.0169,  0.0291,  0.0040,\n",
      "          0.0349, -0.0212, -0.0420,  0.0346, -0.0329, -0.0464, -0.0383, -0.0425],\n",
      "        [ 0.0349,  0.0437,  0.0180, -0.0144, -0.0366, -0.0338,  0.0586, -0.0300,\n",
      "          0.0217, -0.0218, -0.0245, -0.0514, -0.0078,  0.0398, -0.0443, -0.0569,\n",
      "         -0.0492,  0.0033, -0.0155, -0.0412, -0.0289,  0.0309, -0.0135,  0.0136,\n",
      "          0.0279,  0.0593, -0.0210, -0.0345, -0.0387,  0.0600,  0.0037,  0.0583,\n",
      "          0.0242, -0.0462, -0.0520, -0.0128, -0.0284,  0.0441, -0.0337,  0.0059,\n",
      "         -0.0133,  0.0131,  0.0342, -0.0111, -0.0483,  0.0378,  0.0141,  0.0292,\n",
      "         -0.0123, -0.0572, -0.0115, -0.0162,  0.0485,  0.0320,  0.0063, -0.0598,\n",
      "          0.0424, -0.0621,  0.0471,  0.0542, -0.0236,  0.0045, -0.0430, -0.0212,\n",
      "          0.0245, -0.0274, -0.0316,  0.0087,  0.0458, -0.0585, -0.0242, -0.0279,\n",
      "          0.0526,  0.0457, -0.0521, -0.0421, -0.0110, -0.0347, -0.0241, -0.0558,\n",
      "          0.0578,  0.0404,  0.0549,  0.0155,  0.0177,  0.0531, -0.0328, -0.0254,\n",
      "          0.0043, -0.0327,  0.0244, -0.0355,  0.0214,  0.0190, -0.0370,  0.0129,\n",
      "          0.0342,  0.0573,  0.0539,  0.0199, -0.0118,  0.0048,  0.0199,  0.0520,\n",
      "         -0.0040, -0.0095, -0.0363, -0.0574,  0.0353, -0.0311, -0.0199,  0.0011,\n",
      "          0.0102, -0.0413,  0.0083, -0.0341, -0.0567, -0.0074, -0.0102,  0.0348,\n",
      "          0.0347, -0.0082,  0.0577,  0.0105, -0.0009, -0.0131, -0.0587,  0.0160,\n",
      "         -0.0601, -0.0210, -0.0134, -0.0502,  0.0056,  0.0376, -0.0149,  0.0309,\n",
      "          0.0366,  0.0392,  0.0150, -0.0130,  0.0426, -0.0473, -0.0240, -0.0372,\n",
      "          0.0171, -0.0029,  0.0604, -0.0364, -0.0087,  0.0362,  0.0413, -0.0515,\n",
      "         -0.0319, -0.0171, -0.0311, -0.0058, -0.0378,  0.0521,  0.0249, -0.0497,\n",
      "          0.0458,  0.0326, -0.0327, -0.0345, -0.0133,  0.0406,  0.0437,  0.0519,\n",
      "         -0.0523,  0.0465,  0.0174, -0.0451,  0.0174,  0.0588, -0.0584,  0.0588,\n",
      "         -0.0292, -0.0460,  0.0197, -0.0074, -0.0554,  0.0342, -0.0059,  0.0564,\n",
      "          0.0463, -0.0457, -0.0300, -0.0216,  0.0261, -0.0342, -0.0547,  0.0540,\n",
      "         -0.0130,  0.0518, -0.0031,  0.0359, -0.0474, -0.0094, -0.0511, -0.0067,\n",
      "         -0.0581, -0.0217,  0.0053, -0.0518,  0.0027, -0.0443,  0.0063, -0.0044,\n",
      "          0.0276,  0.0377, -0.0249,  0.0536, -0.0117,  0.0247, -0.0106, -0.0481,\n",
      "          0.0343, -0.0207, -0.0475, -0.0151, -0.0164, -0.0561,  0.0103, -0.0467,\n",
      "          0.0232, -0.0398, -0.0143,  0.0329,  0.0379, -0.0340,  0.0528, -0.0571,\n",
      "         -0.0316,  0.0217,  0.0250, -0.0483,  0.0520,  0.0371,  0.0511, -0.0604,\n",
      "          0.0520,  0.0172,  0.0527, -0.0315, -0.0316,  0.0023,  0.0568,  0.0419,\n",
      "          0.0112,  0.0138,  0.0571, -0.0196, -0.0285, -0.0174,  0.0369,  0.0195]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([128]) | Values : tensor([ 0.0118, -0.0303], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([1, 128]) | Values : tensor([[-8.0827e-02, -4.2579e-02, -3.7728e-02,  1.0507e-02, -8.0628e-02,\n",
      "         -5.5218e-02,  4.2329e-02,  5.4565e-02, -2.2081e-02,  3.2482e-02,\n",
      "          4.9409e-02, -7.5483e-02, -8.0990e-03, -6.4184e-02, -6.0422e-02,\n",
      "          5.3407e-02, -4.5851e-02,  8.5999e-02, -3.6208e-02,  4.0319e-02,\n",
      "         -6.6312e-02,  7.4194e-02,  3.7020e-02,  1.9367e-02, -7.7292e-02,\n",
      "         -3.2109e-02, -7.7763e-02,  5.0542e-02,  2.3939e-02,  6.9445e-02,\n",
      "          9.6063e-05,  7.3222e-03, -7.0101e-02,  4.7683e-03,  5.1192e-02,\n",
      "          7.8281e-02,  3.8861e-02, -8.2071e-02,  5.1848e-02, -4.6294e-02,\n",
      "          1.8169e-02,  7.0095e-02,  6.4585e-02, -5.9493e-04,  6.8214e-02,\n",
      "          5.4602e-02,  3.4784e-02,  5.3887e-02,  6.7840e-02, -5.2240e-03,\n",
      "         -5.7340e-02,  4.6590e-02, -6.3706e-02, -6.7709e-02,  3.7702e-02,\n",
      "         -4.7337e-02, -3.5622e-02,  4.7146e-02,  4.1807e-03,  7.5730e-02,\n",
      "          1.6339e-02, -2.6245e-02, -8.7424e-02, -8.2908e-02, -5.1652e-02,\n",
      "          3.8646e-02,  3.7252e-02,  6.3675e-02, -5.4188e-02,  5.3570e-02,\n",
      "          8.3249e-02,  3.7111e-02,  4.6003e-03,  4.9017e-02,  3.5932e-02,\n",
      "          3.2587e-02,  7.0034e-02, -2.7985e-02, -2.2633e-02, -6.6948e-02,\n",
      "         -3.9467e-02, -2.9020e-02,  6.8785e-02,  1.5349e-02,  3.7377e-02,\n",
      "          2.9611e-02,  6.4781e-02,  5.4407e-02,  8.3762e-02,  5.0343e-02,\n",
      "         -4.3370e-02, -5.9864e-02, -5.1413e-02,  3.4380e-02, -4.8859e-02,\n",
      "          2.4290e-02, -4.4111e-02, -2.7926e-02,  6.0262e-02, -4.9340e-02,\n",
      "          8.4785e-02,  8.3175e-02, -8.4367e-02,  7.0964e-02, -3.4611e-02,\n",
      "         -5.7167e-02,  2.9914e-02, -2.8369e-02,  4.8822e-02,  1.0259e-02,\n",
      "         -8.5493e-02,  8.3509e-02, -2.4676e-02, -7.1489e-02,  8.6221e-02,\n",
      "         -5.9530e-02, -8.5910e-02, -8.0751e-02, -1.2016e-02, -3.6904e-02,\n",
      "         -2.9593e-02, -5.6381e-02, -6.4963e-02,  3.2251e-04, -8.3819e-02,\n",
      "         -3.8453e-02, -4.9867e-02, -8.0689e-02]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([1]) | Values : tensor([-0.0418], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1GTxTgp3w3e"
   },
   "source": [
    "#### Neural Network hyperparameters\n",
    "\n",
    "Hyperparameters are adjustable parameters that let you control the model optimization process. Different hyperparameter values can impact model training and convergence rates \n",
    "\n",
    "We define the following hyperparameters for training:\n",
    "- Number of Epochs - the number times to iterate over the dataset\n",
    "- Batch Size - the number of data samples propagated through the network before the parameters are updated\n",
    "- Learning Rate - how much to update models parameters at each batch/epoch. Smaller values yield slow learning speed, while large values may result in unpredictable behavior during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tcjQX7B73wOk"
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDz6D82l3wbk"
   },
   "source": [
    "#### Loss function\n",
    "\n",
    "When presented with some training data, our untrained network is likely not to give the correct answer. Loss function measures the degree of dissimilarity of obtained result to the target value, and it is the loss function that we want to minimize during training. To calculate the loss we make a prediction using the inputs of our given data sample and compare it against the true data label value.\n",
    "\n",
    "Common loss functions include nn.MSELoss (Mean Square Error) for regression tasks, and nn.NLLLoss (Negative Log Likelihood) for classification. nn.CrossEntropyLoss combines nn.LogSoftmax and nn.NLLLoss.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yBsTpjXf4XAc"
   },
   "outputs": [],
   "source": [
    "# Initialize the loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MWcWSK1h4WjG"
   },
   "source": [
    "#### Optimizer\n",
    "\n",
    "Optimization is the process of adjusting model parameters to reduce model error in each training step. Optimization algorithms define how this process is performed (in this example we use Stochastic Gradient Descent). All optimization logic is encapsulated in the optimizer object. Here, we use the SGD optimizer; additionally, there are many different optimizers available in PyTorch such as ADAM and RMSProp, that work better for different kinds of models and data.\n",
    "\n",
    "We initialize the optimizer by registering the model’s parameters that need to be trained, and passing in the learning rate hyperparameter.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VEKbBD8w4iQ2"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2lqp-ek34l9g"
   },
   "source": [
    "Inside the training loop, optimization happens in three steps:\n",
    "\n",
    "- Call optimizer.zero_grad() to reset the gradients of model parameters. Gradients by default add up; to prevent double-counting, we explicitly zero them at each iteration.\n",
    "\n",
    "- Backpropagate the prediction loss with a call to loss.backward(). PyTorch deposits the gradients of the loss w.r.t. each parameter.\n",
    "\n",
    "- Once we have our gradients, we call optimizer.step() to adjust the parameters by the gradients collected in the backward pass.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnPf8L1N4wTr"
   },
   "source": [
    "### The full model and training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bCj0uPwe4sBU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hCElkuQZ4zQk"
   },
   "outputs": [],
   "source": [
    "def train_loop(X_train, Y_train, loss_fn, optimizer):\n",
    "    size = len(X_train)\n",
    "    batch_size = 32\n",
    "    n_batches = int(size/batch_size)\n",
    "    epochs = 50\n",
    "\n",
    "    for epoch_id in range(epochs):\n",
    "      running_loss = []\n",
    "      for batch_id in range(n_batches):\n",
    "          X_batch = X_train[batch_id*batch_size: (batch_id+1)*batch_size]\n",
    "          Y_batch = Y_train[batch_id*batch_size: (batch_id+1)*batch_size]\n",
    "          X_batch = torch.FloatTensor(X_batch)\n",
    "          Y_batch = torch.FloatTensor(Y_batch)\n",
    "\n",
    "          # Compute prediction and loss\n",
    "          pred = model(X_batch)\n",
    "          loss = loss_fn(pred.squeeze(-1), Y_batch)\n",
    "          running_loss.append(loss.item())\n",
    "          \n",
    "          # Backpropagation\n",
    "          optimizer.zero_grad()\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "          loss, current = loss.item(), batch_id * len(X)\n",
    "      print(f\" Epoch: {epoch_id} loss: {np.mean(running_loss):>7f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7YGr6gN7_BG"
   },
   "source": [
    "### RDKit Installation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cuWHJku68CkT",
    "outputId": "3c8ae170-b25f-4041-c41c-740d77e1b39a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-04-30 12:29:14--  https://repo.continuum.io/miniconda/Miniconda3-py37_4.8.3-Linux-x86_64.sh\n",
      "Resolving repo.continuum.io (repo.continuum.io)... 104.18.200.79, 104.18.201.79, 2606:4700::6812:c94f, ...\n",
      "Connecting to repo.continuum.io (repo.continuum.io)|104.18.200.79|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://repo.anaconda.com/miniconda/Miniconda3-py37_4.8.3-Linux-x86_64.sh [following]\n",
      "--2022-04-30 12:29:14--  https://repo.anaconda.com/miniconda/Miniconda3-py37_4.8.3-Linux-x86_64.sh\n",
      "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.130.3, 104.16.131.3, 2606:4700::6810:8303, ...\n",
      "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.130.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 88867207 (85M) [application/x-sh]\n",
      "Saving to: ‘Miniconda3-py37_4.8.3-Linux-x86_64.sh’\n",
      "\n",
      "Miniconda3-py37_4.8 100%[===================>]  84.75M   105MB/s    in 0.8s    \n",
      "\n",
      "2022-04-30 12:29:14 (105 MB/s) - ‘Miniconda3-py37_4.8.3-Linux-x86_64.sh’ saved [88867207/88867207]\n",
      "\n",
      "PREFIX=/usr/local\n",
      "Unpacking payload ...\n",
      "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\bdone\n",
      "Solving environment: - \b\b\\ \b\bdone\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /usr/local\n",
      "\n",
      "  added / updated specs:\n",
      "    - _libgcc_mutex==0.1=main\n",
      "    - ca-certificates==2020.1.1=0\n",
      "    - certifi==2020.4.5.1=py37_0\n",
      "    - cffi==1.14.0=py37he30daa8_1\n",
      "    - chardet==3.0.4=py37_1003\n",
      "    - conda-package-handling==1.6.1=py37h7b6447c_0\n",
      "    - conda==4.8.3=py37_0\n",
      "    - cryptography==2.9.2=py37h1ba5d50_0\n",
      "    - idna==2.9=py_1\n",
      "    - ld_impl_linux-64==2.33.1=h53a641e_7\n",
      "    - libedit==3.1.20181209=hc058e9b_0\n",
      "    - libffi==3.3=he6710b0_1\n",
      "    - libgcc-ng==9.1.0=hdf63c60_0\n",
      "    - libstdcxx-ng==9.1.0=hdf63c60_0\n",
      "    - ncurses==6.2=he6710b0_1\n",
      "    - openssl==1.1.1g=h7b6447c_0\n",
      "    - pip==20.0.2=py37_3\n",
      "    - pycosat==0.6.3=py37h7b6447c_0\n",
      "    - pycparser==2.20=py_0\n",
      "    - pyopenssl==19.1.0=py37_0\n",
      "    - pysocks==1.7.1=py37_0\n",
      "    - python==3.7.7=hcff3b4d_5\n",
      "    - readline==8.0=h7b6447c_0\n",
      "    - requests==2.23.0=py37_0\n",
      "    - ruamel_yaml==0.15.87=py37h7b6447c_0\n",
      "    - setuptools==46.4.0=py37_0\n",
      "    - six==1.14.0=py37_0\n",
      "    - sqlite==3.31.1=h62c20be_1\n",
      "    - tk==8.6.8=hbc83047_0\n",
      "    - tqdm==4.46.0=py_0\n",
      "    - urllib3==1.25.8=py37_0\n",
      "    - wheel==0.34.2=py37_0\n",
      "    - xz==5.2.5=h7b6447c_0\n",
      "    - yaml==0.1.7=had09818_2\n",
      "    - zlib==1.2.11=h7b6447c_3\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
      "  ca-certificates    pkgs/main/linux-64::ca-certificates-2020.1.1-0\n",
      "  certifi            pkgs/main/linux-64::certifi-2020.4.5.1-py37_0\n",
      "  cffi               pkgs/main/linux-64::cffi-1.14.0-py37he30daa8_1\n",
      "  chardet            pkgs/main/linux-64::chardet-3.0.4-py37_1003\n",
      "  conda              pkgs/main/linux-64::conda-4.8.3-py37_0\n",
      "  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.6.1-py37h7b6447c_0\n",
      "  cryptography       pkgs/main/linux-64::cryptography-2.9.2-py37h1ba5d50_0\n",
      "  idna               pkgs/main/noarch::idna-2.9-py_1\n",
      "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.33.1-h53a641e_7\n",
      "  libedit            pkgs/main/linux-64::libedit-3.1.20181209-hc058e9b_0\n",
      "  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_1\n",
      "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0\n",
      "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0\n",
      "  ncurses            pkgs/main/linux-64::ncurses-6.2-he6710b0_1\n",
      "  openssl            pkgs/main/linux-64::openssl-1.1.1g-h7b6447c_0\n",
      "  pip                pkgs/main/linux-64::pip-20.0.2-py37_3\n",
      "  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py37h7b6447c_0\n",
      "  pycparser          pkgs/main/noarch::pycparser-2.20-py_0\n",
      "  pyopenssl          pkgs/main/linux-64::pyopenssl-19.1.0-py37_0\n",
      "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py37_0\n",
      "  python             pkgs/main/linux-64::python-3.7.7-hcff3b4d_5\n",
      "  readline           pkgs/main/linux-64::readline-8.0-h7b6447c_0\n",
      "  requests           pkgs/main/linux-64::requests-2.23.0-py37_0\n",
      "  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.87-py37h7b6447c_0\n",
      "  setuptools         pkgs/main/linux-64::setuptools-46.4.0-py37_0\n",
      "  six                pkgs/main/linux-64::six-1.14.0-py37_0\n",
      "  sqlite             pkgs/main/linux-64::sqlite-3.31.1-h62c20be_1\n",
      "  tk                 pkgs/main/linux-64::tk-8.6.8-hbc83047_0\n",
      "  tqdm               pkgs/main/noarch::tqdm-4.46.0-py_0\n",
      "  urllib3            pkgs/main/linux-64::urllib3-1.25.8-py37_0\n",
      "  wheel              pkgs/main/linux-64::wheel-0.34.2-py37_0\n",
      "  xz                 pkgs/main/linux-64::xz-5.2.5-h7b6447c_0\n",
      "  yaml               pkgs/main/linux-64::yaml-0.1.7-had09818_2\n",
      "  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3\n",
      "\n",
      "\n",
      "Preparing transaction: / \b\b- \b\b\\ \b\b| \b\bdone\n",
      "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
      "installation finished.\n",
      "WARNING:\n",
      "    You currently have a PYTHONPATH environment variable set. This may cause\n",
      "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
      "    For best results, please verify that your PYTHONPATH only points to\n",
      "    directories of packages that are compatible with the Python interpreter\n",
      "    in Miniconda3: /usr/local\n",
      "\n",
      "real\t0m20.445s\n",
      "user\t0m13.157s\n",
      "sys\t0m4.603s\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /usr/local\n",
      "\n",
      "  added / updated specs:\n",
      "    - rdkit\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _openmp_mutex-4.5          |            1_gnu          22 KB\n",
      "    blas-1.0                   |              mkl           6 KB\n",
      "    bottleneck-1.3.4           |   py37hce1f21e_0         126 KB\n",
      "    bzip2-1.0.8                |       h7b6447c_0          78 KB\n",
      "    ca-certificates-2022.3.29  |       h06a4308_1         122 KB\n",
      "    cairo-1.16.0               |       hf32fb01_1         1.0 MB\n",
      "    certifi-2021.10.8          |   py37h06a4308_2         151 KB\n",
      "    conda-4.12.0               |   py37h06a4308_0        14.5 MB\n",
      "    fontconfig-2.13.1          |       h6c09931_0         250 KB\n",
      "    freetype-2.11.0            |       h70c0345_0         618 KB\n",
      "    giflib-5.2.1               |       h7b6447c_0          78 KB\n",
      "    glib-2.69.1                |       h4ff587b_1         1.7 MB\n",
      "    icu-58.2                   |       he6710b0_3        10.5 MB\n",
      "    intel-openmp-2021.4.0      |    h06a4308_3561         4.2 MB\n",
      "    jpeg-9e                    |       h7f8727e_0         240 KB\n",
      "    lcms2-2.12                 |       h3be6417_0         312 KB\n",
      "    libboost-1.73.0            |      h3ff78a5_11        13.9 MB\n",
      "    libgcc-ng-9.3.0            |      h5101ec6_17         4.8 MB\n",
      "    libgomp-9.3.0              |      h5101ec6_17         311 KB\n",
      "    libpng-1.6.37              |       hbc83047_0         278 KB\n",
      "    libtiff-4.2.0              |       h85742a9_0         502 KB\n",
      "    libuuid-1.0.3              |       h7f8727e_2          17 KB\n",
      "    libwebp-1.2.2              |       h55f646e_0          80 KB\n",
      "    libwebp-base-1.2.2         |       h7f8727e_0         440 KB\n",
      "    libxcb-1.14                |       h7b6447c_0         505 KB\n",
      "    libxml2-2.9.12             |       h03d6c58_0         1.2 MB\n",
      "    lz4-c-1.9.3                |       h295c915_1         185 KB\n",
      "    mkl-2021.4.0               |     h06a4308_640       142.6 MB\n",
      "    mkl-service-2.4.0          |   py37h7f8727e_0          56 KB\n",
      "    mkl_fft-1.3.1              |   py37hd3c417c_0         172 KB\n",
      "    mkl_random-1.2.2           |   py37h51133e4_0         287 KB\n",
      "    numexpr-2.8.1              |   py37h6abb31d_0         123 KB\n",
      "    numpy-1.21.5               |   py37he7a7128_1          24 KB\n",
      "    numpy-base-1.21.5          |   py37hf524024_1         4.8 MB\n",
      "    openssl-1.1.1n             |       h7f8727e_0         2.5 MB\n",
      "    packaging-21.3             |     pyhd3eb1b0_0          36 KB\n",
      "    pandas-1.3.4               |   py37h8c16a72_0         9.2 MB\n",
      "    pcre-8.45                  |       h295c915_0         207 KB\n",
      "    pillow-9.0.1               |   py37h22f2fdc_0         652 KB\n",
      "    pixman-0.40.0              |       h7f8727e_1         373 KB\n",
      "    py-boost-1.73.0            |  py37ha9443f7_11         204 KB\n",
      "    pyparsing-3.0.4            |     pyhd3eb1b0_0          81 KB\n",
      "    python-dateutil-2.8.2      |     pyhd3eb1b0_0         233 KB\n",
      "    pytz-2021.3                |     pyhd3eb1b0_0         171 KB\n",
      "    rdkit-2020.09.1.0          |   py37hd50e099_1        25.8 MB  rdkit\n",
      "    zstd-1.4.9                 |       haebb681_0         480 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       244.0 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-4.5-1_gnu\n",
      "  blas               pkgs/main/linux-64::blas-1.0-mkl\n",
      "  bottleneck         pkgs/main/linux-64::bottleneck-1.3.4-py37hce1f21e_0\n",
      "  bzip2              pkgs/main/linux-64::bzip2-1.0.8-h7b6447c_0\n",
      "  cairo              pkgs/main/linux-64::cairo-1.16.0-hf32fb01_1\n",
      "  fontconfig         pkgs/main/linux-64::fontconfig-2.13.1-h6c09931_0\n",
      "  freetype           pkgs/main/linux-64::freetype-2.11.0-h70c0345_0\n",
      "  giflib             pkgs/main/linux-64::giflib-5.2.1-h7b6447c_0\n",
      "  glib               pkgs/main/linux-64::glib-2.69.1-h4ff587b_1\n",
      "  icu                pkgs/main/linux-64::icu-58.2-he6710b0_3\n",
      "  intel-openmp       pkgs/main/linux-64::intel-openmp-2021.4.0-h06a4308_3561\n",
      "  jpeg               pkgs/main/linux-64::jpeg-9e-h7f8727e_0\n",
      "  lcms2              pkgs/main/linux-64::lcms2-2.12-h3be6417_0\n",
      "  libboost           pkgs/main/linux-64::libboost-1.73.0-h3ff78a5_11\n",
      "  libgomp            pkgs/main/linux-64::libgomp-9.3.0-h5101ec6_17\n",
      "  libpng             pkgs/main/linux-64::libpng-1.6.37-hbc83047_0\n",
      "  libtiff            pkgs/main/linux-64::libtiff-4.2.0-h85742a9_0\n",
      "  libuuid            pkgs/main/linux-64::libuuid-1.0.3-h7f8727e_2\n",
      "  libwebp            pkgs/main/linux-64::libwebp-1.2.2-h55f646e_0\n",
      "  libwebp-base       pkgs/main/linux-64::libwebp-base-1.2.2-h7f8727e_0\n",
      "  libxcb             pkgs/main/linux-64::libxcb-1.14-h7b6447c_0\n",
      "  libxml2            pkgs/main/linux-64::libxml2-2.9.12-h03d6c58_0\n",
      "  lz4-c              pkgs/main/linux-64::lz4-c-1.9.3-h295c915_1\n",
      "  mkl                pkgs/main/linux-64::mkl-2021.4.0-h06a4308_640\n",
      "  mkl-service        pkgs/main/linux-64::mkl-service-2.4.0-py37h7f8727e_0\n",
      "  mkl_fft            pkgs/main/linux-64::mkl_fft-1.3.1-py37hd3c417c_0\n",
      "  mkl_random         pkgs/main/linux-64::mkl_random-1.2.2-py37h51133e4_0\n",
      "  numexpr            pkgs/main/linux-64::numexpr-2.8.1-py37h6abb31d_0\n",
      "  numpy              pkgs/main/linux-64::numpy-1.21.5-py37he7a7128_1\n",
      "  numpy-base         pkgs/main/linux-64::numpy-base-1.21.5-py37hf524024_1\n",
      "  packaging          pkgs/main/noarch::packaging-21.3-pyhd3eb1b0_0\n",
      "  pandas             pkgs/main/linux-64::pandas-1.3.4-py37h8c16a72_0\n",
      "  pcre               pkgs/main/linux-64::pcre-8.45-h295c915_0\n",
      "  pillow             pkgs/main/linux-64::pillow-9.0.1-py37h22f2fdc_0\n",
      "  pixman             pkgs/main/linux-64::pixman-0.40.0-h7f8727e_1\n",
      "  py-boost           pkgs/main/linux-64::py-boost-1.73.0-py37ha9443f7_11\n",
      "  pyparsing          pkgs/main/noarch::pyparsing-3.0.4-pyhd3eb1b0_0\n",
      "  python-dateutil    pkgs/main/noarch::python-dateutil-2.8.2-pyhd3eb1b0_0\n",
      "  pytz               pkgs/main/noarch::pytz-2021.3-pyhd3eb1b0_0\n",
      "  rdkit              rdkit/linux-64::rdkit-2020.09.1.0-py37hd50e099_1\n",
      "  zstd               pkgs/main/linux-64::zstd-1.4.9-haebb681_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                                2020.1.1-0 --> 2022.3.29-h06a4308_1\n",
      "  certifi                                 2020.4.5.1-py37_0 --> 2021.10.8-py37h06a4308_2\n",
      "  conda                                        4.8.3-py37_0 --> 4.12.0-py37h06a4308_0\n",
      "  libgcc-ng                                9.1.0-hdf63c60_0 --> 9.3.0-h5101ec6_17\n",
      "  openssl                                 1.1.1g-h7b6447c_0 --> 1.1.1n-h7f8727e_0\n",
      "\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "real\t0m33.929s\n",
      "user\t0m20.677s\n",
      "sys\t0m8.292s\n"
     ]
    }
   ],
   "source": [
    "!wget -c https://repo.continuum.io/miniconda/Miniconda3-py37_4.8.3-Linux-x86_64.sh\n",
    "!chmod +x Miniconda3-py37_4.8.3-Linux-x86_64.sh\n",
    "!time bash ./Miniconda3-py37_4.8.3-Linux-x86_64.sh -b -f -p /usr/local\n",
    "!time conda install -q -y -c rdkit rdkit\n",
    "\n",
    "import sys\n",
    "sys.path.append('/usr/local/lib/python3.7/site-packages/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uPyCsYAJ8FS3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rdkit\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82,
     "referenced_widgets": [
      "33c43065580c4959a05c8611639fc0f8",
      "b94d1514ebdf4672bafaa48c5dd86637",
      "aeff4cc00dd54410bf0383cd2ea81091",
      "810f3eff38a6496baf41ac1cd2aa33c7",
      "1418cff7c02a476e96742a4e758a2188",
      "2200bb567bab4246b7c9eda478e4893c",
      "5e8646de9ee0404f9fb2c9134ea45914",
      "97ca9b75f50a4ea2a7060a01f22f1795",
      "10cb8d845a3f47e6bbad7dfef9071bf5",
      "8484180551194e5eb7e09c90db146652",
      "9553d32abfcd4d85ae94954d67c52cf1"
     ]
    },
    "id": "dtPJnL5V8i1R",
    "outputId": "e5e55e9b-a3b8-4867-9d67-b1775cbe0885"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c43065580c4959a05c8611639fc0f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(902, 512) (113, 512) (113, 512)\n",
      "(902,) (113,) (113,)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./esol.csv')\n",
    "df = df[['measured log solubility in mols per litre','smiles']]\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows()):\n",
    "  smile = row['smiles']\n",
    "  sol = row['measured log solubility in mols per litre']\n",
    "\n",
    "  fingerprint = np.asarray(AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(smile),2,nBits=512))\n",
    "\n",
    "  X.append(fingerprint)\n",
    "  Y.append(sol)\n",
    "\n",
    "X = np.vstack(X)\n",
    "Y=  np.hstack(Y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_valid, X_test, Y_valid, Y_test = train_test_split(X_test, Y_test, test_size=0.5, random_state=42)\n",
    "print(X_train.shape,X_valid.shape,X_test.shape)\n",
    "print(Y_train.shape,Y_valid.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CLIlghqVfbGz"
   },
   "outputs": [],
   "source": [
    "model = model.to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcVPiPpz-Yya"
   },
   "source": [
    "#### Training the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_OyF0kEm8ycu",
    "outputId": "03580ab1-8b46-44a5-bb18-7ec0704911fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0 loss: 12.674489\n",
      " Epoch: 1 loss: 11.373038\n",
      " Epoch: 2 loss: 10.126612\n",
      " Epoch: 3 loss: 8.877158\n",
      " Epoch: 4 loss: 7.604825\n",
      " Epoch: 5 loss: 6.348720\n",
      " Epoch: 6 loss: 5.236157\n",
      " Epoch: 7 loss: 4.428834\n",
      " Epoch: 8 loss: 3.972012\n",
      " Epoch: 9 loss: 3.755182\n",
      " Epoch: 10 loss: 3.646449\n",
      " Epoch: 11 loss: 3.574550\n",
      " Epoch: 12 loss: 3.513891\n",
      " Epoch: 13 loss: 3.456918\n",
      " Epoch: 14 loss: 3.401556\n",
      " Epoch: 15 loss: 3.347135\n",
      " Epoch: 16 loss: 3.293344\n",
      " Epoch: 17 loss: 3.240063\n",
      " Epoch: 18 loss: 3.187191\n",
      " Epoch: 19 loss: 3.134694\n",
      " Epoch: 20 loss: 3.082635\n",
      " Epoch: 21 loss: 3.031038\n",
      " Epoch: 22 loss: 2.979998\n",
      " Epoch: 23 loss: 2.929576\n",
      " Epoch: 24 loss: 2.879701\n",
      " Epoch: 25 loss: 2.830434\n",
      " Epoch: 26 loss: 2.781814\n",
      " Epoch: 27 loss: 2.733915\n",
      " Epoch: 28 loss: 2.686769\n",
      " Epoch: 29 loss: 2.640363\n",
      " Epoch: 30 loss: 2.594876\n",
      " Epoch: 31 loss: 2.550318\n",
      " Epoch: 32 loss: 2.506732\n",
      " Epoch: 33 loss: 2.464096\n",
      " Epoch: 34 loss: 2.422389\n",
      " Epoch: 35 loss: 2.381635\n",
      " Epoch: 36 loss: 2.341772\n",
      " Epoch: 37 loss: 2.302792\n",
      " Epoch: 38 loss: 2.264741\n",
      " Epoch: 39 loss: 2.227716\n",
      " Epoch: 40 loss: 2.191720\n",
      " Epoch: 41 loss: 2.156736\n",
      " Epoch: 42 loss: 2.122637\n",
      " Epoch: 43 loss: 2.089428\n",
      " Epoch: 44 loss: 2.057124\n",
      " Epoch: 45 loss: 2.025715\n",
      " Epoch: 46 loss: 1.995223\n",
      " Epoch: 47 loss: 1.965661\n",
      " Epoch: 48 loss: 1.936942\n",
      " Epoch: 49 loss: 1.909109\n"
     ]
    }
   ],
   "source": [
    "train_loop(X_train, Y_train, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXUMInv5AZtQ"
   },
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pkVSyO4F-ijD"
   },
   "outputs": [],
   "source": [
    "def test_loop(X_test, Y_test, loss_fn):\n",
    "    size = len(X_test)\n",
    "    batch_size = 32\n",
    "    n_batches = int(size/batch_size)\n",
    "    running_loss = []\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for batch_id in range(n_batches):\n",
    "          X_batch = X_test[batch_id*batch_size: (batch_id+1)*batch_size]\n",
    "          Y_batch = Y_test[batch_id*batch_size: (batch_id+1)*batch_size]\n",
    "          X_batch = torch.FloatTensor(X_batch)\n",
    "          Y_batch = torch.FloatTensor(Y_batch)\n",
    "\n",
    "          # Compute prediction and loss\n",
    "          pred = model(X_batch)\n",
    "          loss = loss_fn(pred.squeeze(-1), Y_batch)\n",
    "          running_loss.append(loss.item())\n",
    "\n",
    "          loss, current = loss.item(), batch_id * len(X)\n",
    "\n",
    "          \n",
    "      print(f\" MSE: {np.mean(running_loss):>7f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UfOVmw00Bb_h",
    "outputId": "b157a1e6-d498-46ab-99d0-fde4434a1c89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MSE: 2.050858\n"
     ]
    }
   ],
   "source": [
    "test_loop(X_test, Y_test, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEC24grRBm1v"
   },
   "source": [
    "## Assignment: Toxicity classification\n",
    "\n",
    "\n",
    "You are given a dataset of SMILES and whether they are toxic or not. \n",
    "Task is to create a neural network model for predicting whether a given molecule is toxic or not. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZLrpA9WNBmNw",
    "outputId": "7e314370-73d5-4dce-aafb-3c98dc27f1b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        n_features = 512\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "        nn.Linear(n_features, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 1),\n",
    "    )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i29hKVhzBiID"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sp3-ameXCTIs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Tutorial 7 -Intro-To-PyTorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "10cb8d845a3f47e6bbad7dfef9071bf5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1418cff7c02a476e96742a4e758a2188": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2200bb567bab4246b7c9eda478e4893c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33c43065580c4959a05c8611639fc0f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b94d1514ebdf4672bafaa48c5dd86637",
       "IPY_MODEL_aeff4cc00dd54410bf0383cd2ea81091",
       "IPY_MODEL_810f3eff38a6496baf41ac1cd2aa33c7"
      ],
      "layout": "IPY_MODEL_1418cff7c02a476e96742a4e758a2188"
     }
    },
    "5e8646de9ee0404f9fb2c9134ea45914": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "810f3eff38a6496baf41ac1cd2aa33c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8484180551194e5eb7e09c90db146652",
      "placeholder": "​",
      "style": "IPY_MODEL_9553d32abfcd4d85ae94954d67c52cf1",
      "value": " 1128/? [00:04&lt;00:00, 258.03it/s]"
     }
    },
    "8484180551194e5eb7e09c90db146652": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9553d32abfcd4d85ae94954d67c52cf1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "97ca9b75f50a4ea2a7060a01f22f1795": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "aeff4cc00dd54410bf0383cd2ea81091": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_97ca9b75f50a4ea2a7060a01f22f1795",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_10cb8d845a3f47e6bbad7dfef9071bf5",
      "value": 1
     }
    },
    "b94d1514ebdf4672bafaa48c5dd86637": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2200bb567bab4246b7c9eda478e4893c",
      "placeholder": "​",
      "style": "IPY_MODEL_5e8646de9ee0404f9fb2c9134ea45914",
      "value": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
